{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment_2_[17U03043].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumarsakiv/hunt/blob/master/NLP_Assignment_2_%5B17U03043%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4OOebBuPEnE",
        "colab_type": "text"
      },
      "source": [
        "# **Natural Language Processing**\n",
        "# Assignment 2\n",
        "\n",
        "*   **Submitted By**: Vikas kumar\n",
        "*   **Branch**: IT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMBHlLGGLDAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "050ff4ff-69d1-4ff7-f3d8-25808ae15f1c"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"popular\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7FEiBk0LVA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=\"India is a diverse country with people belonging to different places. People have different cultures, food, clothes and also look different but it doesn’t mean they should be discriminated against. We need to know that Equality is a basic human right and every human being on Earth deserves fair treatment and access to opportunities.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjf9YDFWL0fj",
        "colab_type": "text"
      },
      "source": [
        "**WORD TOKENIZER**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF1_15JRLwvd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d9b45be4-5d62-405c-e2de-372c0aafb50b"
      },
      "source": [
        "from nltk import word_tokenize\n",
        "print(word_tokenize(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['India', 'is', 'a', 'diverse', 'country', 'with', 'people', 'belonging', 'to', 'different', 'places', '.', 'People', 'have', 'different', 'cultures', ',', 'food', ',', 'clothes', 'and', 'also', 'look', 'different', 'but', 'it', 'doesn', '’', 't', 'mean', 'they', 'should', 'be', 'discriminated', 'against', '.', 'We', 'need', 'to', 'know', 'that', 'Equality', 'is', 'a', 'basic', 'human', 'right', 'and', 'every', 'human', 'being', 'on', 'Earth', 'deserves', 'fair', 'treatment', 'and', 'access', 'to', 'opportunities', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdJ5fXnZMLBr",
        "colab_type": "text"
      },
      "source": [
        "**SENTENCE TOKENIZER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4o6R3qhMHKa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9e16f9bd-5601-457c-e8c8-3ac82c21817a"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "print(sent_tokenize(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['India is a diverse country with people belonging to different places.', 'People have different cultures, food, clothes and also look different but it doesn’t mean they should be discriminated against.', 'We need to know that Equality is a basic human right and every human being on Earth deserves fair treatment and access to opportunities.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNYcoRdzMjAq",
        "colab_type": "text"
      },
      "source": [
        "**TREE BANK TOKENIZER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMs2fkNMMgqz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9981610a-6d2a-42d3-86d8-ec2331027d05"
      },
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer \n",
        "  \n",
        "tokenizer = TreebankWordTokenizer() \n",
        "print(tokenizer.tokenize(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['India', 'is', 'a', 'diverse', 'country', 'with', 'people', 'belonging', 'to', 'different', 'places.', 'People', 'have', 'different', 'cultures', ',', 'food', ',', 'clothes', 'and', 'also', 'look', 'different', 'but', 'it', 'doesn', '’', 't', 'mean', 'they', 'should', 'be', 'discriminated', 'against.', 'We', 'need', 'to', 'know', 'that', 'Equality', 'is', 'a', 'basic', 'human', 'right', 'and', 'every', 'human', 'being', 'on', 'Earth', 'deserves', 'fair', 'treatment', 'and', 'access', 'to', 'opportunities', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o725ZRExMqHi",
        "colab_type": "text"
      },
      "source": [
        "**REGULAR EXPRESSION TOKENIZER**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcf_pqOeMtOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "5f40c104-ac64-493b-b6de-b351bc28e780"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer \n",
        "  \n",
        "tokenizer = RegexpTokenizer(\"[\\w']+\") \n",
        "sentence = \"Any serious shift towards sustainable society has to include equality.\"\n",
        "tokenizer.tokenize(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Any',\n",
              " 'serious',\n",
              " 'shift',\n",
              " 'towards',\n",
              " 'sustainable',\n",
              " 'society',\n",
              " 'has',\n",
              " 'to',\n",
              " 'include',\n",
              " 'equality']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB5ZUqolNng8",
        "colab_type": "text"
      },
      "source": [
        "**SPACE TOKENIZER**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzk--Y2GNql8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "290c8404-8cc4-46fe-f8c4-abcd1484eaa6"
      },
      "source": [
        "from nltk import SpaceTokenizer\n",
        "print(SpaceTokenizer().tokenize(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['India', 'is', 'a', 'diverse', 'country', 'with', 'people', 'belonging', 'to', 'different', 'places.', 'People', 'have', 'different', 'cultures,', 'food,', 'clothes', 'and', 'also', 'look', 'different', 'but', 'it', 'doesn’t', 'mean', 'they', 'should', 'be', 'discriminated', 'against.', 'We', 'need', 'to', 'know', 'that', 'Equality', 'is', 'a', 'basic', 'human', 'right', 'and', 'every', 'human', 'being', 'on', 'Earth', 'deserves', 'fair', 'treatment', 'and', 'access', 'to', 'opportunities.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBxET3ulNurl",
        "colab_type": "text"
      },
      "source": [
        "**STOP WORDS REMOVAL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HF6ROKBNyG0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5bcd22ea-b95d-4645-8c99-35c11b58e872"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "word_tokens = word_tokenize(\"Equality is so important because it preserves the “dignity” of an individual. Dignity means self-respect and the respect an individual deserves from others for being a fellow human being. It is an essential and basic human right. However, this ideal case doesn’t exist. Even today, many forms of inequality exist.\")\n",
        "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "filtered_sentence = []\n",
        "\n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "\n",
        "print(\"Stop Words:  \",word_tokens)\n",
        "print(\"Stop Words removed:  \",filtered_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stop Words:   ['Equality', 'is', 'so', 'important', 'because', 'it', 'preserves', 'the', '“', 'dignity', '”', 'of', 'an', 'individual', '.', 'Dignity', 'means', 'self-respect', 'and', 'the', 'respect', 'an', 'individual', 'deserves', 'from', 'others', 'for', 'being', 'a', 'fellow', 'human', 'being', '.', 'It', 'is', 'an', 'essential', 'and', 'basic', 'human', 'right', '.', 'However', ',', 'this', 'ideal', 'case', 'doesn', '’', 't', 'exist', '.', 'Even', 'today', ',', 'many', 'forms', 'of', 'inequality', 'exist', '.']\n",
            "Stop Words removed:   ['Equality', 'important', 'preserves', '“', 'dignity', '”', 'individual', '.', 'Dignity', 'means', 'self-respect', 'respect', 'individual', 'deserves', 'others', 'fellow', 'human', '.', 'It', 'essential', 'basic', 'human', 'right', '.', 'However', ',', 'ideal', 'case', '’', 'exist', '.', 'Even', 'today', ',', 'many', 'forms', 'inequality', 'exist', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbXJgh-xOSPG",
        "colab_type": "text"
      },
      "source": [
        "**STEMMING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzwW9U7NOW4M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fecd8525-6d48-4707-e945-c8158cbaa9a9"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk_tokens = nltk.word_tokenize(text)\n",
        "for w in nltk_tokens:\n",
        "       print(\"Actual: %s  Stem: %s\"  % (w,PorterStemmer().stem(w)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual: India  Stem: india\n",
            "Actual: is  Stem: is\n",
            "Actual: a  Stem: a\n",
            "Actual: diverse  Stem: divers\n",
            "Actual: country  Stem: countri\n",
            "Actual: with  Stem: with\n",
            "Actual: people  Stem: peopl\n",
            "Actual: belonging  Stem: belong\n",
            "Actual: to  Stem: to\n",
            "Actual: different  Stem: differ\n",
            "Actual: places  Stem: place\n",
            "Actual: .  Stem: .\n",
            "Actual: People  Stem: peopl\n",
            "Actual: have  Stem: have\n",
            "Actual: different  Stem: differ\n",
            "Actual: cultures  Stem: cultur\n",
            "Actual: ,  Stem: ,\n",
            "Actual: food  Stem: food\n",
            "Actual: ,  Stem: ,\n",
            "Actual: clothes  Stem: cloth\n",
            "Actual: and  Stem: and\n",
            "Actual: also  Stem: also\n",
            "Actual: look  Stem: look\n",
            "Actual: different  Stem: differ\n",
            "Actual: but  Stem: but\n",
            "Actual: it  Stem: it\n",
            "Actual: doesn  Stem: doesn\n",
            "Actual: ’  Stem: ’\n",
            "Actual: t  Stem: t\n",
            "Actual: mean  Stem: mean\n",
            "Actual: they  Stem: they\n",
            "Actual: should  Stem: should\n",
            "Actual: be  Stem: be\n",
            "Actual: discriminated  Stem: discrimin\n",
            "Actual: against  Stem: against\n",
            "Actual: .  Stem: .\n",
            "Actual: We  Stem: We\n",
            "Actual: need  Stem: need\n",
            "Actual: to  Stem: to\n",
            "Actual: know  Stem: know\n",
            "Actual: that  Stem: that\n",
            "Actual: Equality  Stem: equal\n",
            "Actual: is  Stem: is\n",
            "Actual: a  Stem: a\n",
            "Actual: basic  Stem: basic\n",
            "Actual: human  Stem: human\n",
            "Actual: right  Stem: right\n",
            "Actual: and  Stem: and\n",
            "Actual: every  Stem: everi\n",
            "Actual: human  Stem: human\n",
            "Actual: being  Stem: be\n",
            "Actual: on  Stem: on\n",
            "Actual: Earth  Stem: earth\n",
            "Actual: deserves  Stem: deserv\n",
            "Actual: fair  Stem: fair\n",
            "Actual: treatment  Stem: treatment\n",
            "Actual: and  Stem: and\n",
            "Actual: access  Stem: access\n",
            "Actual: to  Stem: to\n",
            "Actual: opportunities  Stem: opportun\n",
            "Actual: .  Stem: .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maK8hEG8OcNf",
        "colab_type": "text"
      },
      "source": [
        "**LEMMATIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFep_fmQOe8M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61ef7055-b30f-479a-b603-5034d295a716"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk_tokens = nltk.word_tokenize(text)\n",
        "for w in nltk_tokens:\n",
        "       print(\"Actual: %s --->  Lemma: %s\"  % (w,WordNetLemmatizer().lemmatize(w)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual: India --->  Lemma: India\n",
            "Actual: is --->  Lemma: is\n",
            "Actual: a --->  Lemma: a\n",
            "Actual: diverse --->  Lemma: diverse\n",
            "Actual: country --->  Lemma: country\n",
            "Actual: with --->  Lemma: with\n",
            "Actual: people --->  Lemma: people\n",
            "Actual: belonging --->  Lemma: belonging\n",
            "Actual: to --->  Lemma: to\n",
            "Actual: different --->  Lemma: different\n",
            "Actual: places --->  Lemma: place\n",
            "Actual: . --->  Lemma: .\n",
            "Actual: People --->  Lemma: People\n",
            "Actual: have --->  Lemma: have\n",
            "Actual: different --->  Lemma: different\n",
            "Actual: cultures --->  Lemma: culture\n",
            "Actual: , --->  Lemma: ,\n",
            "Actual: food --->  Lemma: food\n",
            "Actual: , --->  Lemma: ,\n",
            "Actual: clothes --->  Lemma: clothes\n",
            "Actual: and --->  Lemma: and\n",
            "Actual: also --->  Lemma: also\n",
            "Actual: look --->  Lemma: look\n",
            "Actual: different --->  Lemma: different\n",
            "Actual: but --->  Lemma: but\n",
            "Actual: it --->  Lemma: it\n",
            "Actual: doesn --->  Lemma: doesn\n",
            "Actual: ’ --->  Lemma: ’\n",
            "Actual: t --->  Lemma: t\n",
            "Actual: mean --->  Lemma: mean\n",
            "Actual: they --->  Lemma: they\n",
            "Actual: should --->  Lemma: should\n",
            "Actual: be --->  Lemma: be\n",
            "Actual: discriminated --->  Lemma: discriminated\n",
            "Actual: against --->  Lemma: against\n",
            "Actual: . --->  Lemma: .\n",
            "Actual: We --->  Lemma: We\n",
            "Actual: need --->  Lemma: need\n",
            "Actual: to --->  Lemma: to\n",
            "Actual: know --->  Lemma: know\n",
            "Actual: that --->  Lemma: that\n",
            "Actual: Equality --->  Lemma: Equality\n",
            "Actual: is --->  Lemma: is\n",
            "Actual: a --->  Lemma: a\n",
            "Actual: basic --->  Lemma: basic\n",
            "Actual: human --->  Lemma: human\n",
            "Actual: right --->  Lemma: right\n",
            "Actual: and --->  Lemma: and\n",
            "Actual: every --->  Lemma: every\n",
            "Actual: human --->  Lemma: human\n",
            "Actual: being --->  Lemma: being\n",
            "Actual: on --->  Lemma: on\n",
            "Actual: Earth --->  Lemma: Earth\n",
            "Actual: deserves --->  Lemma: deserves\n",
            "Actual: fair --->  Lemma: fair\n",
            "Actual: treatment --->  Lemma: treatment\n",
            "Actual: and --->  Lemma: and\n",
            "Actual: access --->  Lemma: access\n",
            "Actual: to --->  Lemma: to\n",
            "Actual: opportunities --->  Lemma: opportunity\n",
            "Actual: . --->  Lemma: .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55aBeqH1PVxl",
        "colab_type": "text"
      },
      "source": [
        "*--End of File: Assignment 2; *"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaAzBK5vcFVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}